import Foundation

actor TranscriptionService {
  private let hephAPI: HephAPI
  private let ollamaAPI: OllamaAPI
  private let recordingStore: RecordingStoreActor
  
  init(hephAPI: HephAPI = HephAPI(),
       ollamaAPI: OllamaAPI = OllamaAPI(),
       recordingStore: RecordingStoreActor) {
    self.hephAPI = hephAPI
    self.ollamaAPI = ollamaAPI
    self.recordingStore = recordingStore
  }
  
  func transcribe(recording: RecordingModel) async throws {
    print("ğŸ¯ é–‹å§‹è½‰éŒ„æµç¨‹: \(recording.title)")
    print("ğŸ“‚ éŸ³æª”è·¯å¾‘: \(recording.filePath)")
    
    // ä¸Šå‚³éŸ³æª”
    let task = try await hephAPI.uploadAudio(fileURL: URL(filePath: recording.filePath))
    
    // ç­‰å¾…è½‰éŒ„å®Œæˆ
    print("â³ ç­‰å¾…è½‰éŒ„å®Œæˆ...")
    var status = try await hephAPI.checkStatus(taskID: task.data.task_id)
    while status.data.status != "Completed" {
      try await Task.sleep(for: .seconds(2))
      status = try await hephAPI.checkStatus(taskID: task.data.task_id)
    }
    
    // å–å¾—è½‰éŒ„çµæœ
    print("ğŸ”„ å–å¾—è½‰éŒ„çµæœ...")
    let result = try await hephAPI.getResult(taskID: task.data.task_id)
    
    // æ›´æ–°éŒ„éŸ³è³‡è¨Š
    print("ğŸ“ æ›´æ–°éŒ„éŸ³è³‡è¨Š...")
    let updatedRecording = recording
    updatedRecording.transcript = result.text
    
    // ç”Ÿæˆæ‘˜è¦
    print("ğŸ¤– ç”Ÿæˆ AI æ‘˜è¦...")
    let summary = try await ollamaAPI.generateSummary(text: result.text)
    updatedRecording.summary = summary
    
    // å„²å­˜æ›´æ–°
    print("ğŸ’¾ å„²å­˜æ›´æ–°...")
    try await recordingStore.update(updatedRecording)
    print("âœ… è½‰éŒ„æµç¨‹å®Œæˆ!")
  }
}
